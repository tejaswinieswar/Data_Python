{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, json, shutil\n",
    "from shutil import copyfile\n",
    "path_to_json = '/Users/Sneha/Documents/files_for_python/DataAnalysis4Python_Spring17/Assignment 2/Data'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "os.mkdir( path_to_json+'/Data_Processed', 777 );\n",
    "os.chmod(path_to_json+'/Data_Processed', int('0755') )\n",
    "rest=[]\n",
    "hotel=[]\n",
    "att=[]\n",
    "for js in json_files:#to check the key term in the json files\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "        p=json.load(json_file)\n",
    "        z= str(p)\n",
    "        if (z.find(\"'term': 'restaurants'\")!= -1):\n",
    "            rest.append(js)\n",
    "        elif(z.find(\"'term': 'hotels'\")!= -1):\n",
    "            hotel.append(js)\n",
    "        elif(z.find(\"'term': 'attractions'\")!= -1):\n",
    "            att.append(js)\n",
    "        else:\n",
    "            print(\"This is invlaid category\")\n",
    "            break\n",
    "os.mkdir( path_to_json+'/Data_Processed/Restaurants_Processed', 777 );\n",
    "os.chmod(path_to_json+'/Data_Processed/Restaurants_Processed', int('0755') )\n",
    "os.mkdir( path_to_json+'/Data_Processed/Hotels_Processed', 777 );\n",
    "os.chmod(path_to_json+'/Data_Processed/Hotels_Processed', int('0755'))\n",
    "os.mkdir( path_to_json+'/Data_Processed/Attractions_Processed', 777 );\n",
    "os.chmod(path_to_json+'/Data_Processed/Attractions_Processed', int('0755') )\n",
    "dict_files1={}\n",
    "dict_files2={}\n",
    "dict_files3={}\n",
    "def perform_function(dict_files,path_orig,loop_list):#Function to seggregate the files into hierachical folders\n",
    "    for a in loop_list:\n",
    "        with open(os.path.join(path_to_json, a)) as j_file:\n",
    "            p=json.load(j_file)\n",
    "            #print (p)\n",
    "            #print (type(p))\n",
    "            loc= p['location']\n",
    "            country=loc['country']\n",
    "            #print(country)\n",
    "            if country not in dict_files:\n",
    "                l =[]\n",
    "                l.append(a)\n",
    "                dict_files[country]= l\n",
    "            else:\n",
    "                temp_list= dict_files[country]\n",
    "                temp_list.append(a)\n",
    "                dict_files[country]=temp_list\n",
    "    #print (dict_files)\n",
    "    for i in dict_files:\n",
    "        #print (i)\n",
    "        t_list= dict_files[i]\n",
    "        #print (t_list)\n",
    "        os.mkdir( path_to_json+path_orig+'/'+i, 777 );\n",
    "        os.chmod(path_to_json+path_orig+'/'+i, int('0755') )\n",
    "        for n in t_list:\n",
    "            shutil.move(path_to_json+'/'+n,path_to_json+path_orig+'/'+i+'/'+n)\n",
    "perform_function(dict_files1,'/Data_Processed/Restaurants_Processed',rest)\n",
    "perform_function(dict_files2,'/Data_Processed/Hotels_Processed',hotel)\n",
    "perform_function(dict_files3,'/Data_Processed/Attractions_Processed',att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_2=open('ques2_partb.csv', 'a')\n",
    "title='Name of restaurant'+','+'City'+','+'Country Code'+','+'Day of week'+','+'Start Time'+','+'End time'+'\\n'\n",
    "csv_2.write(title)\n",
    "for a in rest:\n",
    "        with open(os.path.join(path_to_json, a)) as j_file:\n",
    "            #print(a)\n",
    "            p=json.load(j_file)\n",
    "            #print(p)\n",
    "            if 'hours' in p:\n",
    "                open_hours=p['hours']\n",
    "                #print(type(open_hours))\n",
    "                open_h=(open_hours[0])\n",
    "                open_open=open_h['open']\n",
    "                #print(open_open)\n",
    "                loc=p['location']\n",
    "                for z in open_open:\n",
    "                    row=str(p['name'])+','+str(loc['city'])+','+str(loc['country'])+','+str(z['day'])+','+str(z['start'])+','+str(z['end'])+'\\n'\n",
    "                    #print (row)\n",
    "                    csv_2.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
